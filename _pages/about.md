---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

**å¼ ä¸‰ä¹‰**ï¼Œä¸­å›½ä¼ åª’å¤§å­¦ æ•°æ®ç§‘å­¦ä¸æ™ºèƒ½åª’ä½“å­¦é™¢ å‰¯æ•™æˆï¼Œä¸­å›½ä¼ åª’å¤§å­¦é’å¹´æ‹”å°–äººæ‰å…¥é€‰è€…ã€‚ä¸»è¦ç ”ç©¶æ–¹å‘æ˜¯äººå·¥æ™ºèƒ½ã€è®¡ç®—æœºè§†è§‰ã€äººç‰©å›¾åƒæ™ºèƒ½æ„ŸçŸ¥ã€‚2021å¹´åšå£«æ¯•ä¸šäºå¤©æ´¥å¤§å­¦ç”µæ°”è‡ªåŠ¨åŒ–ä¸ä¿¡æ¯å·¥ç¨‹å­¦é™¢ä¿¡æ¯ä¸é€šä¿¡å·¥ç¨‹ä¸“ä¸šï¼ŒæŒ‡å¯¼å¯¼å¸ˆæ˜¯[å‘¨æ°æ•™æˆ](https://www.au.tsinghua.edu.cn/info/1110/1583.htm)å’Œ[å®‹å æ°æ•™æˆ](https://math.tju.edu.cn/info/1715/6541.htm)ï¼Œ2018-2019ç¾å›½ä¸­ä½›ç½—é‡Œè¾¾å¤§å­¦è”åˆåŸ¹å…»åšå£«ï¼ŒæŒ‡å¯¼å¯¼å¸ˆä¸º[Guo-Jun Qiæ•™æˆ](http://maple-lab.net/gqi/)ã€‚ä¸­å›½ç§‘å­¦é™¢ä¿¡æ¯å·¥ç¨‹ç ”ç©¶æ‰€ åŸä¿¡æ¯å®‰å…¨å›½å®¶é‡ç‚¹å®éªŒå®¤ åšå£«åï¼ˆç‰¹åˆ«ç ”ç©¶åŠ©ç†ï¼‰ï¼ŒæŒ‡å¯¼å¯¼å¸ˆä¸º[æ“æ™“æ˜¥æ•™æˆ]([https://scst.sysu.edu.cn/members/caoxiaochun.htm])ã€‚ä¸»æŒæ‰¿æ‹…äº†å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é’å¹´é¡¹ç›®ã€åšå£«åç§‘å­¦åŸºé‡‘é¢ä¸Šé¡¹ç›®ã€ç§‘æŠ€éƒ¨é‡ç‚¹ç ”å‘é¡¹ç›®å­è¯¾é¢˜ã€‚ 
åœ¨IEEE TIPã€T-CSVTã€CVPRç­‰å›½å†…å¤–å­¦æœ¯æœŸåˆŠå’Œä¼šè®®ä¸Šå‘è¡¨è®ºæ–‡9ç¯‡ï¼Œå…¶ä¸­ä»¥ç¬¬ä¸€ä½œè€…å‘è¡¨IEEE Trans. 3ç¯‡ï¼Œå¹¶æ‹…ä»»äº†IEEE TIP/TMM/TCSVTã€CVPRã€ACM MMã€AAAIã€ICCVç­‰å›½é™…æœŸåˆŠå’Œä¼šè®®çš„å®¡ç¨¿äººã€‚æ›¾è£è·å…¨å›½åšå£«åäººå·¥æ™ºèƒ½å‘å±•ä¸åº”ç”¨è®ºå›ä¼˜ç§€è®ºæ–‡äºŒç­‰å¥–ã€åŒ—äº¬å›¾è±¡å›¾å½¢å­¦å­¦ä¼šBSIG2022å¹´ä¼˜ç§€åšå£«è®ºæ–‡æåå¥–ç­‰ã€‚

Hi! I am **Sanyi Zhang**. I am an Associate Professor at the School of Data Science and Media Intelligence, Communication University of China (CUC), Beijing, China. Before joining CUC, I was a Postdoctoral Scholar working with Prof. Xiaochun Cao in the State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences. I received my Ph.D. degree in the School of Electrical and Information Engineering, Tianjin University, China, supervised by Prof. Jie Zhou and Prof. Zhanjie Song. I received the B.E. and M.E. degrees in Computer Science and Technology, Taiyuan University of Technology, P.R.  China.  I was a visiting student at the Institute of Information Engineering, Chinese Academy of Sciences, working with Prof. Xiaochun Cao. From 2018 to 2019, I was a visiting Ph.D. student at the Department of Computer Science, University of Central Florida, working with Prof. Guo-jun Qi. 
My current research interests include computer vision, human parsing, and clothing attribute learning.

# ğŸ”¥ News
- *2023.09*: &nbsp; One model robustness paper is accepted by IEEE Transactions on Image Processing (TIP) 2023.

- *2023.07*: &nbsp; One camouflaged object detection paper is accepted by ACM MM 2023.
  
- *2022.08*: &nbsp; Two papers are accepted by IEEE Transactions on Image Processing (TIP) 2022.

- *2021.03*: &nbsp; Our text detection paper is accepted by CVPR 2021.

- *2020.04*: &nbsp; One human parsing paper is accepted by T-CSVT 2020.

- *2019*: &nbsp; One co-author's paper is accepted by IEEE Transactions on Geoscience and Remote Sensing (T-GRS).

- *2019*: &nbsp; One paper is accepted in T-CSVT 2019.

- *2018*: &nbsp; One paper is accepted in Neurocomputing 2018.
# ğŸ“ Selected Publications 


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TIP 2023</div><img src='images/first_new_page-0001.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
Exploring the Robustness of Human Parsers Towards Common Corruptions

**Sanyi Zhang**, Xiaochun Cao, Rui Wang, Guo-Jun Qi, Jie Zhou

[**Code**](https://github.com/31sy/HeterAug/) / [**Paper**](https://ieeexplore.ieee.org/document/10254479) /  [**arxiv**](https://export.arxiv.org/abs/2309.00938) /<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

IEEE Transactions on Image Processing (TIP) 2023,  
<font color=purple>Impact factor: 10.6</font>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2023</div><img src='images/MM23_COD.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[Frequency Perception Network for Camouflaged Object Detection](https://arxiv.org/abs/2308.08924)

Runmin Cong, Mengyao Sun, **Sanyi Zhang**, Xiaofei Zhou, Wei Zhang, and Yao Zhao

[**Code**](https://github.com/rmcong/FPNet_ACMMM23) / [**Paper**](https://arxiv.org/abs/2308.08924) /  <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

ACM Multimedia (ACM MM) 2023,  
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TIP 2022</div><img src='images/first-serial-edge.png' alt="sym" width="100%">
</div></div>
<div class='paper-box-text' markdown="1">
[AIParsing: Anchor-free Instance-level Human Parsing](https://arxiv.org/abs/2207.06854)

**Sanyi Zhang**, Xiaochun Cao, Guo-Jun Qi, Zhanjie Song, and Jie Zhou

[**Code**](https://github.com/31sy/AIParsing) / [**Paper**](https://arxiv.org/abs/2207.06854) / [**Poster**](images/TIP-AIParsing.jpeg) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

IEEE Transactions on Image Processing (TIP) 2022,  
<font color=purple>Impact factor: 10.6</font>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TIP 2022</div><img src='images/ACE.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">


[ACE: Anchor-free Corner Evolution for Real-time Arbitrarily-oriented Object Detection](https://ieeexplore.ieee.org/abstract/document/9761381)

Pengwen Dai, Siyuan Yao, Zekun Li, **Sanyi Zhang**, and Xiaochun Cao 

[**Code**]() / [**Paper**](https://ieeexplore.ieee.org/abstract/document/9761381) / <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

IEEE Transactions on Image Processing (TIP) 2022,
<font color=purple>Impact factor: 10.6</font>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2021</div><img src='images/motivation_v1.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">


[Progressive Contour Regression for Arbitrary-Shape Scene Text Detection](https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_Progressive_Contour_Regression_for_Arbitrary-Shape_Scene_Text_Detection_CVPR_2021_paper.pdf)

Pengwen Dai, **Sanyi Zhang**, Hua Zhang, Xiaochun Cao 

[**Code**](https://github.com/dpengwen/PCR) / [**Paper**](https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_Progressive_Contour_Regression_for_Arbitrary-Shape_Scene_Text_Detection_CVPR_2021_paper.pdf) / <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

IEEE CVPR 2021,
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TCSVT 2021</div><img src='images/framework_PGECNet.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">


[Human Parsing with Pyramidical Gather-Excite Context](https://ieeexplore.ieee.org/document/9078888/)

**Sanyi Zhang**, Guo-jun Qi, Xiaochun Cao*, Zhanjie Song, and Jie Zhou

[**Code**](https://github.com/31sy/PGECNet) / [**Paper**](https://ieeexplore.ieee.org/document/9078888) / <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

IEEE Transactions on Circuits and Systems for Video Technology (T-CSVT), 2021,
<font color=purple>Impact factor: 8.4</font>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TCSVT 2020</div><img src='images/TAN.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">


[Task-aware Attention Model for Clothing Attribute Prediction](https://ieeexplore.ieee.org/document/8654674)

**Sanyi Zhang**, Zhanjie Song, Xiaochun Cao*, Hua Zhang and Jie Zhou

[**Code**](https://github.com/31sy/Clothing_TAN) / [**Paper**](https://ieeexplore.ieee.org/document/8654674) / <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

IEEE Transactions on Circuits and Systems for Video Technology (T-CSVT), 2020,
<font color=purple>Impact factor: 8.4</font>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TGRS 2019</div><img src='images/LV-Net.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">


[Nested Network with Two-Stream Pyramid for Salient Object Detection in Optical Remote Sensing Images](https://ieeexplore.ieee.org/document/8654674)

Chongyi Li, Runmin Cong, Junhui Hou, **Sanyi Zhang**, Yue Qian, Sam Kwong

[**Code**](https://li-chongyi.github.io/proj_optical_saliency.html) / [**Paper**](https://ieeexplore.ieee.org/abstract/document/8793227)/ [**arxiv**](https://arxiv.org/abs/1906.08462) / <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

IEEE Transactions on Geoscience and Remote Sensing (T-GRS), 2019,
<font color=purple>Impact factor: 8.2</font>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NC 2018</div><img src='images/NC_first.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">


[Watch Fashion Shows to Tell Clothing Attributes](https://www.sciencedirect.com/science/article/pii/S092523121731860X)

**Sanyi Zhang**, Si Liu, Xiaochun Cao, Zhanjie Song* and Jie Zhou

[**Dataset**](https://tjueducn-my.sharepoint.com/:f:/g/personal/zhangsanyi_tju_edu_cn/EvKIbE0U-QVEhuXjxKk_H2QB_vLvu5Uubo1cdqlYx-xfaw) / [**Paper**](https://www.sciencedirect.com/science/article/pii/S092523121731860X) / <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>

Neurocomputing, 2018,
<font color=purple>Impact factor: 6.0</font>
</div>
</div>

- More papers are being submitted, or please visit my [Google Scholar](https://scholar.google.com/citations?user=n8TL-xkAAAAJ&hl=en) or [DBLP](https://dblp.org/pid/214/3977.html) to view all papers.

# ğŸ– Honors and Awards
- *2023.12* **ç¬¬ä¸‰å±Šä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ç ”ç©¶ç”Ÿè®ºå› æ°å‡ºæŠ¥å‘Šå¥–**
- *2022.05* **åŒ—äº¬å›¾è±¡å›¾å½¢å­¦å­¦ä¼šBSIG2022å¹´ä¼˜ç§€åšå£«è®ºæ–‡æåå¥–**
- *2019.12* **å…¨å›½åšå£«åäººå·¥æ™ºèƒ½å‘å±•ä¸åº”ç”¨è®ºå› äºŒç­‰å¥–**
- *2017.12* **ä¸­ç§‘é™¢ä¿¡æ¯å·¥ç¨‹ç ”ç©¶æ‰€ æ‰€é•¿ç‰¹åˆ«å¥–**
- *2017.10* **å¤©æ´¥å¤§å­¦åšå£«ç”Ÿè®ºå›ç”µæ°”ä¸ä¿¡æ¯å·¥ç¨‹EIEåˆ†è®ºå›å­¦æœ¯è®ºæ–‡ä¼˜ç§€å¥–**

# å·¥ä½œç»å†
*2024.06 - è‡³ä»Š*,  å‰¯æ•™æˆï¼Œæ•°æ®ç§‘å­¦ä¸æ™ºèƒ½åª’ä½“å­¦é™¢ï¼Œä¸­å›½ä¼ åª’å¤§å­¦ï¼Œä¸­å›½åŒ—äº¬

# ğŸ“– Educations
- *2021.07 - 2024.05*,  åšå£«åï¼Œä¿¡æ¯å®‰å…¨å›½å®¶é‡ç‚¹å®éªŒå®¤ï¼Œä¸­å›½ç§‘å­¦é™¢ä¿¡æ¯å·¥ç¨‹ç ”ç©¶æ‰€ï¼Œä¸­å›½åŒ—äº¬ï¼ŒæŒ‡å¯¼è€å¸ˆï¼šæ“æ™“æ˜¥ æ•™æˆ
- *2018.09 - 2019.09*, CSCè”åŸ¹åšå£«ç”Ÿï¼Œè®¡ç®—æœºç§‘å­¦ï¼Œä¸­ä½›ç½—é‡Œè¾¾å¤§å­¦ï¼ˆUCFï¼‰ï¼Œç¾å›½å¥¥å…°å¤šï¼ŒæŒ‡å¯¼è€å¸ˆï¼šGuo-Jun Qi åŠ©ç†æ•™æˆ 
- *2015.09 - 2021.06*,  åšå£«ï¼Œä¿¡æ¯ä¸é€šä¿¡å·¥ç¨‹ï¼Œå¤©æ´¥å¤§å­¦ï¼Œä¸­å›½å¤©æ´¥ï¼ŒæŒ‡å¯¼è€å¸ˆï¼šå‘¨æ° æ•™æˆ  å®‹å æ° æ•™æˆ
- *2011.09 - 2014.07*,  ç¡•å£«ï¼Œè®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ï¼Œå¤ªåŸç†å·¥å¤§å­¦ï¼Œä¸­å›½å¤ªåŸï¼ŒæŒ‡å¯¼è€å¸ˆï¼šå¼ å…´å¿  æ•™æˆ
- *2007.09 - 2011.07*,  æœ¬ç§‘ï¼Œè®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ï¼Œå¤ªåŸç†å·¥å¤§å­¦ï¼Œä¸­å›½å¤ªåŸ 

# ğŸ’¬ Professional Service

- *æœŸåˆŠå®¡ç¨¿äºº*: IEEE Transactions on Image Processing (TIP), IEEE Transactions on Multimedia (TMM), IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 
ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), IEEE Computational Intelligence Magazine (CIM)
- *ä¼šè®®å®¡ç¨¿äºº*ï¼šACM MM 2020-2023, NeurIPS 2022, IEEE CVPR 2023, AAAI 2023, IJCAI 2023, ICCV 2023ï¼Œ AAAI 2024.

<a href="https://info.flagcounter.com/UFld"><img src="https://s01.flagcounter.com/count2/UFld/bg_FFFFFF/txt_070801/border_CCCCCC/columns_2/maxflags_6/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
